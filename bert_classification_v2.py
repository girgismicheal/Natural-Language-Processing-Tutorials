# -*- coding: utf-8 -*-
"""BERT_classification_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzUykBNkcEoJmCVwBn84alzdfX4qtwqn
"""

import numpy as np
from sklearn.model_selection import KFold
# data sample
data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])
# prepare cross validation
kfold = KFold(n_splits=3, shuffle=True, random_state=1)
# enumerate splits
for train, test in kfold.split(data):
  print('train: %s, test: %s' % (data[train], data[test]))

pip install simpletransformers

from simpletransformers.classification import ClassificationModel
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import pandas as pd

#dataset
dataset = [["Example sentence belonging to class 1", 1],
               ["Example sentence belonging to class 0", 0],
               ["Example eval sentence belonging to class 1", 1],
         ["Example eval sentence belonging to class 0", 0]]
train_data = pd.DataFrame(dataset)
 
# prepare cross validation
n=2
seed=2
kf = KFold(n_splits=n, random_state=seed, shuffle=True)

results = []

for train_index, val_index in kf.split(train_data):
# splitting Dataframe (dataset not included)
    train_df = train_data.iloc[train_index]
    val_df = train_data.iloc[val_index]
# Defining Model
    model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=False, args={'reprocess_input_data': True, 'overwrite_output_dir': True})
# train the model
    model.train_model(train_df)
# validate the model
    result, model_outputs, wrong_predictions = model.eval_model(val_df, acc=accuracy_score)
    print(result['acc'])
# append model score
    results.append(result['acc'])

"""https://chanalytics-ai.medium.com/text-classification-with-simpletransformers-f8912372531b

https://www.philschmid.de/k-fold-as-cross-validation-with-a-bert-text-classification-example
"""