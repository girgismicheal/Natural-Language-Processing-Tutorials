{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross_Validation_v1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2hezg1zDW08",
        "outputId": "1c5c90de-513b-4ba9-b98e-c3b4d82f9856"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X.shape, y.shape\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lYtgU4jUeLC",
        "outputId": "e52e7a45-91a5-46f5-cc87-d11b3751671b"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI7IXB2pUrH0",
        "outputId": "f1e65337-3398-4012-d3eb-ce6d847aec38"
      },
      "source": [
        "\n",
        "#splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = svm.SVC(kernel='linear', C=1)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "scores\n",
        "\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ6fstDuU9lQ",
        "outputId": "4e5e16e8-08b4-4297-af34-e96c59af7b63"
      },
      "source": [
        "\n",
        "#passing a cross validation iterator;\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "n_samples = X.shape[0]\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "cross_val_score(clf, X, y, cv=cv)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVkyfQohVNQu",
        "outputId": "1bc61899-9f1a-4c8d-c2be-1b6f754b3bc9"
      },
      "source": [
        "#test a predictor on data held-out from training, preprocessing (such as standardization, feature selection etc.)\n",
        "from sklearn import preprocessing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.4, random_state=0)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
        "X_test_transformed = scaler.transform(X_test)\n",
        "clf.score(X_test_transformed, y_test)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al95AVmaVVU4",
        "outputId": "f8662bc0-e94a-44ab-b46f-7d5a121e5362"
      },
      "source": [
        "# using pipelines put you at ease with transformations or composing estimators;\n",
        "from sklearn.pipeline import make_pipeline\n",
        "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
        "cross_val_score(clf, X, y, cv=cv)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xy4Lz7UVn_U",
        "outputId": "42549940-153a-40b9-9280-4196e9af2ff2"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "X = [\"a\", \"b\", \"c\", \"d\"]\n",
        "kf = KFold(n_splits=4)\n",
        "for train, test in kf.split(X):\n",
        "     print(\"%s %s\" % (train, test))\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "X = np.arange(10)\n",
        "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
        "for train_index, test_index in ss.split(X):\n",
        "    print(\"%s %s\" % (train_index, test_index))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3] [0]\n",
            "[0 2 3] [1]\n",
            "[0 1 3] [2]\n",
            "[0 1 2] [3]\n",
            "[9 1 6 7 3 0 5] [2 8 4]\n",
            "[2 9 8 0 6 7 4] [3 5 1]\n",
            "[4 5 1 0 6 9 7] [2 3 8]\n",
            "[2 7 5 8 0 3 4] [6 1 9]\n",
            "[4 1 0 6 8 9 3] [5 2 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiQGw9IyWD0g",
        "outputId": "f3015484-7785-4223-d783-750cd640670c"
      },
      "source": [
        "    \n",
        "# scikit-learn k-fold cross-validation\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "# data sample\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "# prepare cross validation\n",
        "kfold = KFold(3, True, 1)\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(data):\n",
        "\tprint('train: %s, test: %s' % (data[train], data[test]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.1 0.4 0.5 0.6], test: [0.2 0.3]\n",
            "train: [0.2 0.3 0.4 0.6], test: [0.1 0.5]\n",
            "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv1BBlyyUQJO"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"cross_validation_v1.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1mdElAQFaCLmg8ZWrsMbwhAOhk25HQ0_h\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X.shape, y.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "#splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = svm.SVC(kernel='linear', C=1)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "scores\n",
        "\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "#passing a cross validation iterator;\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "n_samples = X.shape[0]\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
        "cross_val_score(clf, X, y, cv=cv)\n",
        "\n",
        "#test a predictor on data held-out from training, preprocessing (such as standardization, feature selection etc.)\n",
        "from sklearn import preprocessing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.4, random_state=0)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
        "X_test_transformed = scaler.transform(X_test)\n",
        "clf.score(X_test_transformed, y_test)\n",
        "\n",
        "# using pipelines put you at ease with transformations or composing estimators;\n",
        "from sklearn.pipeline import make_pipeline\n",
        "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
        "cross_val_score(clf, X, y, cv=cv)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "X = [\"a\", \"b\", \"c\", \"d\"]\n",
        "kf = KFold(n_splits=4)\n",
        "for train, test in kf.split(X):\n",
        "     print(\"%s %s\" % (train, test))\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "X = np.arange(10)\n",
        "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
        "for train_index, test_index in ss.split(X):\n",
        "    print(\"%s %s\" % (train_index, test_index))\n",
        "    \n",
        "    \n",
        "    \n",
        "# scikit-learn k-fold cross-validation\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "# data sample\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "# prepare cross validation\n",
        "kfold = KFold(3, True, 1)\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(data):\n",
        "\tprint('train: %s, test: %s' % (data[train], data[test]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}